"""
Competitor Ad Intelligence Hub (Streamlit ç‰ˆ)

æ€è·¯ï¼š
- æ•°æ®æºï¼šæœ¬åœ° Apify å¯¼å‡ºçš„ Facebook Ads JSONï¼ˆMockï¼Œé˜²æ­¢ API æ²¡é¢åº¦ï¼‰
- æ¸…æ´—ä¸èšåˆï¼šåŒè½¨åˆ¶ URL å»é‡ + æ–‡æ¡ˆæŒ‡çº¹ï¼Œè®¡ç®— Intensityï¼ˆçƒ­åº¦ï¼‰
- å¤šæ¨¡æ€åˆ†æï¼šä¸‹è½½ Top3 å›¾ç‰‡ + æ–‡æ¡ˆï¼Œä¸Šä¼ åˆ° Geminiï¼Œç”Ÿæˆ Insight + Midjourney Prompt
- å‰ç«¯ï¼šStreamlit å•é¡µåº”ç”¨ï¼ˆé¡¶éƒ¨ AI æˆ˜ç•¥å¡ç‰‡ + åº•éƒ¨ç´ æç”»å»Šï¼‰
"""

from __future__ import annotations

import json
import os
import time
import tempfile
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List

from dotenv import load_dotenv
from google import genai
from google.genai import types
import requests
import streamlit as st


# ================= 1. é…ç½®ä¸ Mock æ•°æ® =================

load_dotenv()

st.set_page_config(
    page_title="Competitor Ad Intelligence Hub",
    layout="wide",
    page_icon="âš¡ï¸",
)


def fetch_ads_from_apify(url: str, api_token: str, results_limit: int = 50) -> List[Dict[str, Any]]:
    """
    è°ƒç”¨ Apify Actor (facebook-ads-scraper) çˆ¬å–æ•°æ®
    """
    if not api_token:
        st.error("æœªé…ç½® Apify API Token")
        return []

    # Actor ID for facebook-ads-scraper.
    actor_id = "apify~facebook-ads-scraper"

    # 1. Start the actor run
    run_url = f"https://api.apify.com/v2/acts/{actor_id}/runs?token={api_token}"

    # Input configuration for the actor
    actor_input = {
        "startUrls": [{"url": url}],
        "resultsLimit": results_limit,  # Limit to avoid long waits
        "viewMode": "list",
        "renderType": "html"
    }

    try:
        with st.status("æ­£åœ¨å¯åŠ¨ Apify çˆ¬è™«...", expanded=True) as status:
            st.write(f"ğŸš€ æ­£åœ¨å¯åŠ¨ Actor: {actor_id}...")
            resp = requests.post(run_url, json=actor_input)
            if resp.status_code != 201:
                status.update(label="Apify å¯åŠ¨å¤±è´¥", state="error")
                st.error(f"Apify start run failed: {resp.text}")
                return []

            run_data = resp.json().get("data", {})
            run_id = run_data.get("id")
            if not run_id:
                st.error("No run ID returned from Apify.")
                return []

            st.write(f"â³ ä»»åŠ¡å·²æäº¤ (Run ID: {run_id})ï¼Œæ­£åœ¨ç­‰å¾…å®Œæˆ...")

            # 2. Poll for completion
            max_retries = 100  # Prevent infinite loop (approx 5 mins)
            retry_count = 0
            while retry_count < max_retries:
                status_url = f"https://api.apify.com/v2/actor-runs/{run_id}?token={api_token}"
                status_resp = requests.get(status_url)
                status_data = status_resp.json().get("data", {})
                run_status = status_data.get("status")

                if run_status == "SUCCEEDED":
                    st.write("âœ… çˆ¬å–å®Œæˆï¼")
                    status.update(label="çˆ¬å–æˆåŠŸ", state="complete", expanded=False)
                    break
                elif run_status in ["FAILED", "ABORTED", "TIMED-OUT"]:
                    status.update(label="çˆ¬å–å¤±è´¥", state="error")
                    st.error(f"Apify run failed with status: {run_status}")
                    return []

                time.sleep(3)  # Wait 3 seconds before next poll
                retry_count += 1
            
            if retry_count >= max_retries:
                status.update(label="çˆ¬å–è¶…æ—¶", state="error")
                st.error("Apify run timed out.")
                return []

            # 3. Fetch dataset items
            dataset_id = status_data.get("defaultDatasetId")
            if not dataset_id:
                st.error("No dataset ID found.")
                return []

            dataset_url = f"https://api.apify.com/v2/datasets/{dataset_id}/items?token={api_token}"
            st.write(f"æ­£åœ¨è·å–æ•°æ®é›†: {dataset_id}...")
            dataset_resp = requests.get(dataset_url)
            if dataset_resp.status_code == 200:
                data = dataset_resp.json()
                st.write(f"å…±è·å– {len(data)} æ¡æ•°æ®ã€‚")
                return data
            else:
                st.error(f"Failed to fetch dataset items: {dataset_resp.text}")
                return []

    except Exception as e:
        st.error(f"Error fetching ads from Apify: {e}")
        return []


# ================= 2. æ•°æ®æ¸…æ´—ä¸å»é‡ =================

def get_clean_url(url: str | None) -> str:
    """æå–æŒ‡çº¹ URLï¼ˆå»é™¤ ? åçš„å‚æ•°ï¼‰ï¼Œåªç”¨äºå»é‡ï¼Œä¸ç”¨äºå±•ç¤ºã€‚"""
    if not url:
        return ""
    return url.split("?", 1)[0]


@st.cache_data(show_spinner=False)
def process_ads(raw_ads: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    æ ¸å¿ƒæ¸…æ´—ä¸å»é‡é€»è¾‘ï¼š
    1. åŒºåˆ†è§†é¢‘/å›¾ç‰‡å¹¿å‘Šï¼Œåˆ†åˆ«æå–é¢„è§ˆå›¾
    2. ç”ŸæˆæŒ‡çº¹ Key (æ–‡æ¡ˆå‰ 50 å­— + å¹²å‡€å›¾ç‰‡/è§†é¢‘é¢„è§ˆ URL)
    3. èšåˆè®¡ç®—çƒ­åº¦ (Intensity)
    
    ä¿ç•™å­—æ®µï¼š
    - adArchiveID, pageID, pageName, startDateFormatted
    - snapshot: body.text, ctaText, linkUrl, title, displayFormat
    - snapshot: images, videos, cards
    """
    grouped_ads: Dict[str, Dict[str, Any]] = {}

    for ad in raw_ads:
        snapshot = ad.get("snapshot", {}) or {}
        
        # --- åŸºç¡€ä¿¡æ¯ ---
        ad_archive_id = ad.get("adArchiveID") or ""
        page_id = ad.get("pageID") or ""
        page_name = ad.get("pageName") or ""
        start_date = ad.get("startDateFormatted") or ""
        
        # --- Snapshot å†…å®¹ ---
        body = snapshot.get("body") or {}
        body_text = body.get("text") or ""
        
        # --- è·å–åŸå§‹åˆ—è¡¨ (éœ€è¦å…ˆè·å– cards ä»¥ä¾¿åç»­ fallback) ---
        cards = snapshot.get("cards") or []
        images = snapshot.get("images") or []
        videos = snapshot.get("videos") or []
        
        # å¦‚æœ body_text ä¸ºç©ºæˆ–åŒ…å«æ¨¡æ¿å˜é‡ï¼Œå°è¯•ä» cards[0].body è·å–ï¼ˆDCO/è½®æ’­å¹¿å‘Šæ–‡æ¡ˆï¼‰
        def is_template_variable(text: str) -> bool:
            """æ£€æµ‹æ˜¯å¦åŒ…å« DCO æ¨¡æ¿å˜é‡å¦‚ {{product.brand}}"""
            return bool(text) and "{{" in text and "}}" in text
        
        if (not body_text or is_template_variable(body_text)) and cards:
            card_body = (cards[0] or {}).get("body") or ""
            # cards ä¸­çš„ body å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
            if isinstance(card_body, dict):
                card_body = card_body.get("text") or ""
            if card_body and not is_template_variable(card_body):
                body_text = card_body
        
        cta_text = snapshot.get("ctaText") or "Learn More"
        link_url = snapshot.get("linkUrl") or ""
        display_format = snapshot.get("displayFormat") or ""  # VIDEO / IMAGE ç­‰
        
        # --- A. åˆ¤æ–­æ˜¯å¦ä¸ºè§†é¢‘å¹¿å‘Š ---
        is_video = display_format == "VIDEO" or bool(videos)
        
        # --- B. æ™ºèƒ½æå–é¢„è§ˆå›¾ & è§†é¢‘é“¾æ¥ ---
        preview_image_url = ""
        video_hd_url = ""
        
        if is_video:
            # è§†é¢‘å¹¿å‘Šï¼špreview ä½¿ç”¨ videoPreviewImageUrlï¼Œé™„ä¸Š videoHdUrl
            if videos:
                video0 = videos[0] or {}
                preview_image_url = video0.get("videoPreviewImageUrl") or ""
                video_hd_url = video0.get("videoHdUrl") or video0.get("videoSdUrl") or ""
            # å¦‚æœ videos ä¸ºç©ºï¼Œå°è¯•ä» cards è·å–
            if not video_hd_url and cards:
                card0 = cards[0] or {}
                video_hd_url = card0.get("videoHdUrl") or card0.get("videoUrl") or ""
                if not preview_image_url:
                    preview_image_url = card0.get("videoPreviewImageUrl") or card0.get("originalImageUrl") or ""
        else:
            # å›¾ç‰‡å¹¿å‘Šï¼špreview ä½¿ç”¨ originalImageUrl
            if cards:
                # è½®æ’­å¡ç‰‡ï¼šå–ç¬¬ä¸€å¼ å³å¯ï¼ˆå»é‡ï¼‰
                card0 = cards[0] or {}
                preview_image_url = card0.get("originalImageUrl") or card0.get("resizedImageUrl") or ""
            elif images:
                img0 = images[0] or {}
                preview_image_url = img0.get("originalImageUrl") or img0.get("resizedImageUrl") or ""
        
        # --- C. æå–æ ‡é¢˜ ---
        # ä¼˜å…ˆçº§ï¼šsnapshot.title -> cards[0].title -> ä» body_text æˆªå– -> å…œåº• "Sponsored Ad"
        title = snapshot.get("title") or ""
        
        # å¦‚æœ title ä¸ºç©ºæˆ–åŒ…å«æ¨¡æ¿å˜é‡ï¼Œä» cards è·å–
        if (not title or is_template_variable(title)) and cards:
            title = (cards[0] or {}).get("title") or ""
        
        # å¦‚æœä»ç„¶æ— æ•ˆï¼Œä» body_text æˆªå–å‰ 50 ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
        if (not title or is_template_variable(title)) and body_text:
            # å–ç¬¬ä¸€è¡Œæˆ–å‰ 50 å­—ç¬¦
            first_line = body_text.split("\n")[0].strip()
            title = first_line[:50] + ("..." if len(first_line) > 50 else "")
        
        if not title or is_template_variable(title):
            title = "Sponsored Ad"
        
        # --- D. ç”ŸæˆæŒ‡çº¹ (Fingerprint) ---
        # ç”¨äºå»é‡ï¼šæ–‡æ¡ˆå‰50å­— + å¹²å‡€çš„é¢„è§ˆå›¾ URL
        clean_preview_url = get_clean_url(preview_image_url)
        fingerprint_key = f"{body_text[:50]}_{clean_preview_url}"
        
        # --- E. èšåˆé€»è¾‘ ---
        if fingerprint_key in grouped_ads:
            grouped_ads[fingerprint_key]["intensity"] += 1
            grouped_ads[fingerprint_key]["ad_ids"].append(ad_archive_id)
        else:
            grouped_ads[fingerprint_key] = {
                # æŒ‡çº¹ & å»é‡
                "key": fingerprint_key,
                "intensity": 1,
                "ad_ids": [ad_archive_id],
                
                # åŸºç¡€ä¿¡æ¯
                "ad_archive_id": ad_archive_id,
                "page_id": page_id,
                "page_name": page_name,
                "start_date": start_date,
                
                # åˆ›æ„å†…å®¹
                "title": title,
                "text": body_text,
                "cta": cta_text,
                "link_url": link_url,
                "display_format": display_format,
                
                # åª’ä½“èµ„æº
                "is_video": is_video,
                "preview_image_url": preview_image_url,  # ç»Ÿä¸€çš„é¢„è§ˆå›¾
                "video_hd_url": video_hd_url,  # è§†é¢‘å¹¿å‘Šæ‰æœ‰
                
                # åŸå§‹æ•°æ®ï¼ˆç”¨äºè¯¦æƒ…å±•ç¤ºï¼‰
                "cards": cards,
                "images": images,
                "videos": videos,
            }

    # è½¬ä¸ºåˆ—è¡¨å¹¶æŒ‰çƒ­åº¦å€’åºæ’åˆ—
    return sorted(grouped_ads.values(), key=lambda x: x["intensity"], reverse=True)


# ================= 2.5 æ—¶é—´ç­›é€‰ =================

TIME_FILTER_OPTIONS = {
    "å…¨éƒ¨": None,
    "è¿‡å» 48 å°æ—¶": 48,
    "è¿‡å» 72 å°æ—¶": 72,
    "è¿‡å» 1 å‘¨": 168,
}


def filter_ads_by_time(ads: List[Dict[str, Any]], hours: int | None) -> List[Dict[str, Any]]:
    """
    æ ¹æ®æŠ•æ”¾å¼€å§‹æ—¶é—´è¿‡æ»¤å¹¿å‘Š
    hours: è¿‡å»å¤šå°‘å°æ—¶å†…çš„å¹¿å‘Šï¼ŒNone è¡¨ç¤ºä¸è¿‡æ»¤
    """
    if hours is None:
        return ads
    
    cutoff = datetime.now(timezone.utc) - timedelta(hours=hours)
    filtered = []
    
    for ad in ads:
        start_date_str = ad.get("start_date") or ""
        try:
            # æ ¼å¼: "2025-11-03T08:00:00.000Z"
            start_date = datetime.fromisoformat(start_date_str.replace("Z", "+00:00"))
            if start_date >= cutoff:
                filtered.append(ad)
        except (ValueError, TypeError):
            # è§£æå¤±è´¥åˆ™ä¿ç•™
            filtered.append(ad)
    
    return filtered


# ================= 3. å¤šæ¨¡æ€ Gemini åˆ†æ =================

SYSTEM_PROMPT = """
**Role (è§’è‰²):**
ä½ æ˜¯æœåŠ¡äºåŒ—ç¾é¡¶çº§ DTC å“ç‰Œçš„é«˜çº§ç«å“æƒ…æŠ¥åˆ†æå¸ˆã€‚
ä½ ç²¾é€šæ¶ˆè´¹è€…å¿ƒç†å­¦ã€è§†è§‰è®¾è®¡è¶‹åŠ¿ä»¥åŠ Meta å¹¿å‘ŠæŠ•æ”¾ç­–ç•¥ï¼Œä¸“æ³¨äºä»ç«å“å¹¿å‘Šä¸­æŒ–æ˜å¯å€Ÿé‰´çš„åˆ›æ„çµæ„Ÿå’Œä¿ƒé”€æƒ…æŠ¥ã€‚

**Task (ä»»åŠ¡):**
æ·±åº¦åˆ†æè¾“å…¥çš„ä¸€ç»„ç«å“å¹¿å‘Šå›¾ç‰‡å’Œæ–‡æ¡ˆï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. ç«å“å½“å‰çš„ä¿ƒé”€åŠ¨æ€ï¼ˆæŠ˜æ‰£åŠ›åº¦ã€æ´»åŠ¨ä¸»é¢˜ã€ç´§è¿«æ„Ÿè¥é€ ï¼‰
2. å¯å€Ÿé‰´çš„åˆ›æ„å…ƒç´ ï¼ˆè§†è§‰é£æ ¼ã€æ–‡æ¡ˆç­–ç•¥ã€Hook è®¾è®¡ï¼‰
3. æ•´ä½“æŠ•æ”¾ç­–ç•¥è¶‹åŠ¿

**--- æ ¸å¿ƒåˆ†ææ¡†æ¶ ---**

**1. ç´ æç±»å‹åˆ†ç±»:**
* **è®¾è®¡ç±»å‹:** Render(æ¸²æŸ“) / Real Shot(å®æ‹) / UGCé£æ ¼
* **å†…å®¹ç­–ç•¥:** Traffic(ç§è‰) / Promotion(å¤§ä¿ƒ) / Conversion(è½¬åŒ–)

**2. åˆ›æ„æ‹†è§£ç»´åº¦:**
* **è§†è§‰äº®ç‚¹:** Hookå…ƒç´ ã€åœºæ™¯ã€ç»“æ„ã€å¯å€Ÿé‰´ç‚¹
* **æ–‡æ¡ˆäº®ç‚¹:** æ¡†æ¶(PAS/BAB)ã€æƒ…ç»ªè§¦å‘è¯ã€ç›®æ ‡å—ä¼—ã€å¯å€Ÿé‰´ç‚¹

**3. ä¿ƒé”€æƒ…æŠ¥:** æŠ˜æ‰£åŠ›åº¦ã€æ´»åŠ¨åç§°ã€ç´§è¿«æ„Ÿå…ƒç´ 

**--- OUTPUT FORMAT ---**

è¾“å‡ºä¸¥æ ¼çš„ JSONï¼ˆä¸è¦ç”¨ Markdown ä»£ç å—åŒ…è£¹ï¼‰ï¼š

{
  "overall_analysis": {
    "promotion_intel": "ç«å“å½“å‰ä¿ƒé”€åŠ¨æ€æ€»ç»“",
    "creative_trend": "åˆ›æ„é£æ ¼è¶‹åŠ¿æ€»ç»“",
    "key_takeaways": "å¯å€Ÿé‰´çš„æ ¸å¿ƒè¦ç‚¹ï¼ˆåˆ—å‡º2-3æ¡ï¼‰"
  },
  "individual_ads": [
    {
      "index": 0,
      "category": {
        "design_type": "Render - åœºæ™¯æ¸²æŸ“",
        "content_strategy": "Promotion"
      },
      "visual_highlights": {
        "hook_element": "ç¬¬ä¸€çœ¼çœ‹åˆ°çš„æ˜¯...",
        "scene": "æˆ·å¤–éœ²è¥åœºæ™¯",
        "structure": "äº§å“ç‰¹å†™+ä¿ƒé”€æ–‡å­—",
        "worth_learning": "å¯å€Ÿé‰´ç‚¹ï¼š..."
      },
      "copy_highlights": {
        "framework": "PAS",
        "target_audience": "ä»·æ ¼æ•æ„Ÿçš„æˆ·å¤–çˆ±å¥½è€…",
        "emotional_triggers": ["Save", "Limited", "Now"],
        "worth_learning": "å¯å€Ÿé‰´ç‚¹ï¼š..."
      },
      "promo_intel": {
        "discount": "$1,400 OFF (48%)",
        "campaign_name": "æ´»åŠ¨åç§°",
        "urgency_elements": ["Limited-time"]
      },
      "creative_score": 8,
      "one_line_summary": "ä¸€å¥è¯æ€»ç»“è¿™æ¡å¹¿å‘Šçš„æ ¸å¿ƒå–ç‚¹å’Œå¯å€Ÿé‰´ä¹‹å¤„"
    }
  ]
}
"""


def download_image_to_temp(image_url: str) -> str | None:
    """
    ä¸‹è½½å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„
    """
    try:
        resp = requests.get(image_url, timeout=30)
        if resp.status_code != 200:
            return None
        
        # æ ¹æ® Content-Type ç¡®å®šåç¼€
        content_type = resp.headers.get("Content-Type", "image/jpeg")
        if "png" in content_type:
            suffix = ".png"
        elif "gif" in content_type:
            suffix = ".gif"
        elif "webp" in content_type:
            suffix = ".webp"
        else:
            suffix = ".jpg"
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as f:
            f.write(resp.content)
            return f.name
    except Exception as e:
        st.warning(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {e}")
        return None


def upload_image_to_gemini(client: genai.Client, image_url: str) -> Any | None:
    """
    ä¸‹è½½å›¾ç‰‡å¹¶ä¸Šä¼ åˆ° Gemini File API
    è¿”å›å¯ç”¨äº generate_content çš„ file å¯¹è±¡
    """
    temp_path = download_image_to_temp(image_url)
    if not temp_path:
        return None
    
    try:
        uploaded_file = client.files.upload(file=temp_path)
        return uploaded_file
    except Exception as e:
        st.warning(f"å›¾ç‰‡ä¸Šä¼ åˆ° Gemini å¤±è´¥: {e}")
        return None
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(temp_path)
        except:
            pass


def analyze_with_gemini(api_key: str, groups: List[Dict[str, Any]]) -> Dict[str, Any] | None:
    """
    ä½¿ç”¨ Gemini è¿›è¡Œå¤šæ¨¡æ€åˆ†æï¼ˆä»…å›¾ç‰‡ç´ æ + æ–‡æ¡ˆï¼‰
    é€šè¿‡ File API ä¸Šä¼ å›¾ç‰‡ï¼Œé¿å… token æµªè´¹
    æ³¨æ„ï¼šæš‚æ—¶åªåˆ†æå›¾ç‰‡å¹¿å‘Šï¼Œè§†é¢‘å¹¿å‘Šè·³è¿‡
    """
    if not api_key:
        return None

    try:
        client = genai.Client(api_key=api_key)
        
        # æ„å»º prompt å†…å®¹
        contents: List[Any] = [SYSTEM_PROMPT]
        
        # åªç­›é€‰å›¾ç‰‡å¹¿å‘Šè¿›è¡Œåˆ†æ
        image_ads = [g for g in groups if not g.get("is_video", False)]
        
        if not image_ads:
            st.warning("æ²¡æœ‰å›¾ç‰‡å¹¿å‘Šå¯ä¾›åˆ†æï¼Œå½“å‰ä»…æ”¯æŒå›¾ç‰‡ç´ æåˆ†æã€‚")
            return None
        
        # åˆ†æ Top 5 å›¾ç‰‡å¹¿å‘Š
        top = image_ads[:5]
        uploaded_count = 0
        
        for i, g in enumerate(top):
            # æ·»åŠ æ–‡æ¡ˆæè¿°ï¼ˆä½¿ç”¨ä¸­æ–‡æ ¼å¼ï¼‰
            contents.append(f"\n\nå¹¿å‘Š #{i}:\næ ‡é¢˜: {g['title']}\næ–‡æ¡ˆ: {g['text'][:500]}")
            
            # ä¸Šä¼ å›¾ç‰‡åˆ° File API
            image_url = g.get("preview_image_url")
            if image_url:
                with st.spinner(f"æ­£åœ¨ä¸Šä¼ å›¾ç‰‡ {i+1}/{len(top)}..."):
                    uploaded_file = upload_image_to_gemini(client, image_url)
                    if uploaded_file:
                        contents.append(uploaded_file)
                        uploaded_count += 1
        
        if uploaded_count == 0:
            st.warning("æ²¡æœ‰æˆåŠŸä¸Šä¼ ä»»ä½•å›¾ç‰‡ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
            return None
        
        # è°ƒç”¨ Gemini
        with st.spinner(f"æ­£åœ¨å¯¹ {uploaded_count} å¼ å›¾ç‰‡è¿›è¡Œæ·±åº¦åˆ›æ„åˆ†æ..."):
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=contents
            )
        
        result_text = response.text
        if not result_text:
            return None

        raw = result_text.strip()

        # æ¸…ç† ```json ``` åŒ…è£¹
        if "```json" in raw:
            raw = raw.split("```json", 1)[1].split("```", 1)[0]
        elif "```" in raw:
            raw = raw.split("```", 1)[1].split("```", 1)[0]

        try:
            return json.loads(raw)
        except Exception:
            # å¦‚æœä¸æ˜¯ä¸¥æ ¼ JSONï¼Œåˆ™åšå…œåº•ï¼ˆä½¿ç”¨æ–°çš„ JSON ç»“æ„ï¼‰
            st.warning("Gemini è¿”å›å†…å®¹ä¸æ˜¯ä¸¥æ ¼ JSONï¼Œå°†ä»¥çº¯æ–‡æœ¬å½¢å¼å±•ç¤ºã€‚")
            return {
                "overall_analysis": {
                    "promotion_intel": result_text,
                    "creative_trend": "æ¨¡å‹æœªè¿”å›ç»“æ„åŒ– JSON",
                    "key_takeaways": "è¯·æ£€æŸ¥è¿”å›å†…å®¹"
                },
                "individual_ads": []
            }

    except Exception as e:
        st.error(f"Gemini API Error: {e}")
        return {
            "overall_analysis": {
                "promotion_intel": f"Gemini API Error: {str(e)}",
                "creative_trend": "Error",
                "key_takeaways": "Error"
            },
            "individual_ads": []
        }


# ================= 4. å¼¹çª—ç»„ä»¶ =================

@st.dialog("å¹¿å‘Šè¯¦æƒ…")
def show_ad_details(ad: Dict[str, Any]):
    st.markdown(f"### {ad['title']}")
    
    # åª’ä½“å±•ç¤º
    if ad['is_video'] and ad['video_hd_url']:
        st.video(ad['video_hd_url'])
    elif ad['preview_image_url']:
        st.image(ad['preview_image_url'], use_container_width=True)
    
    # åŸºç¡€ä¿¡æ¯
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"**å¹¿å‘Šä¸»:** {ad['page_name']}")
        st.markdown(f"**æ ¼å¼:** {ad['display_format'] or 'N/A'}")
    with col2:
        st.markdown(f"**CTA:** {ad['cta']}")
        st.markdown(f"**æŠ•æ”¾æ—¥æœŸ:** {ad['start_date']}")
    
    st.divider()
    
    # æ–‡æ¡ˆ
    st.markdown("**ğŸ“ å®Œæ•´æ–‡æ¡ˆ:**")
    st.write(ad["text"])
    
    # é“¾æ¥
    if ad['link_url']:
        st.markdown(f"**ğŸ”— è½åœ°é¡µ:** [{ad['link_url'][:50]}...]({ad['link_url']})")
    
    # è§†é¢‘é“¾æ¥
    if ad['is_video'] and ad['video_hd_url']:
        st.markdown(f"**ğŸ¥ è§†é¢‘é“¾æ¥:** [è§‚çœ‹è§†é¢‘]({ad['video_hd_url']})")
    
    # è¯¦ç»†æ•°æ®
    with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹æ•°æ®"):
        st.json(ad)


# ================= 4. ä¸»ç•Œé¢ UI =================

st.title("ğŸš€ Competitor Ad Intelligence Hub (V3.0)")
st.markdown("### å…¨è¡Œä¸šé€šç”¨ç‰ˆ | å¤šæ¨¡æ€ AI åˆ†æ")

# --- Sidebar ---
with st.sidebar:
    st.header("âš™ï¸ é…ç½®ä¸­å¿ƒ")
    
    # ä¼˜å…ˆè¯»å– st.secrets, å…¶æ¬¡ os.getenv (æ”¯æŒ .env)
    secrets_gemini = st.secrets.get("GEMINI_API_KEY") or ""
    secrets_apify = st.secrets.get("APIFY_API_TOKEN") or ""
    env_gemini = os.getenv("GEMINI_API_KEY") or ""
    env_apify = os.getenv("APIFY_API_TOKEN") or ""
    
    # å¦‚æœ secrets ä¸­å·²é…ç½®ï¼Œåˆ™éšè—è¾“å…¥æ¡†ï¼Œç›´æ¥ä½¿ç”¨ secrets
    has_secrets = bool(secrets_gemini and secrets_apify)
    
    if has_secrets:
        # Secrets å·²é…ç½®ï¼Œä¸æ˜¾ç¤ºè¾“å…¥æ¡†
        gemini_key = secrets_gemini
        apify_token = secrets_apify
        st.success("âœ… API å·²é…ç½®ï¼Œå¯ç›´æ¥ä½¿ç”¨")
    else:
        # æœªé…ç½® secretsï¼Œæ˜¾ç¤ºè¾“å…¥æ¡†è®©ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥
        default_gemini = secrets_gemini or env_gemini
        default_apify = secrets_apify or env_apify
        
        gemini_key = st.text_input("Gemini API Key", value=default_gemini, type="password")
        apify_token = st.text_input("Apify API Token", value=default_apify, type="password")
    
    st.divider()
    
    results_limit = st.number_input("çˆ¬å–æ•°é‡é™åˆ¶ (Max Results)", min_value=1, max_value=500, value=10, step=10)
    
    # æ—¶é—´ç­›é€‰
    time_filter_label = st.selectbox(
        "â±ï¸ æ—¶é—´ç­›é€‰",
        options=list(TIME_FILTER_OPTIONS.keys()),
        index=0
    )
    time_filter_hours = TIME_FILTER_OPTIONS[time_filter_label]

    st.divider()
    if not has_secrets:
        st.info("ğŸ’¡ è¯·è¾“å…¥ Apify Token ä»¥è°ƒç”¨çˆ¬è™«ï¼Œä»¥åŠ Gemini Key è¿›è¡Œåˆ†æã€‚")

# --- åˆå§‹åŒ– Session State ---
if "processed_ads" not in st.session_state:
    st.session_state.processed_ads = []
if "ai_report" not in st.session_state:
    st.session_state.ai_report = None
if "brand_library" not in st.session_state:
    st.session_state.brand_library = []
if "current_scan_url" not in st.session_state:
    st.session_state.current_scan_url = ""

# --- Tabs ---
tab_quick_scan, tab_brand_library = st.tabs(["ğŸ” Quick Scan", "ğŸ“š Brand Library"])


# ================= Helper: æ¸²æŸ“å¹¿å‘Šç»“æœ =================
def render_ad_results(ads: List[Dict[str, Any]], ai_report: Dict[str, Any] | None, key_prefix: str = ""):
    """æ¸²æŸ“ AI åˆ†æç»“æœå’Œå¹¿å‘Šç”»å»Šï¼ˆåˆå¹¶å±•ç¤ºï¼‰"""
    
    # --- æ•´ä½“ç­–ç•¥åˆ†æ ---
    if ai_report:
        st.subheader("ğŸ¤– ç«å“æƒ…æŠ¥æ€»è§ˆ")
        overall = ai_report.get("overall_analysis", {})
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("**ï¿½ ä¿ƒé”€åŠ¨æ€**")
            st.info(overall.get("promotion_intel", "æš‚æ— æ•°æ®"))
        with col2:
            st.markdown("**ğŸ¨ åˆ›æ„è¶‹åŠ¿**")
            st.success(overall.get("creative_trend", "æš‚æ— æ•°æ®"))
        with col3:
            st.markdown("**ğŸ’¡ å¯å€Ÿé‰´è¦ç‚¹**")
            st.warning(overall.get("key_takeaways", "æš‚æ— æ•°æ®"))
        
        st.divider()
    
    # --- ç´ æç”»å»Š + åˆ†æåˆå¹¶å±•ç¤º ---
    st.subheader(f"ğŸ”¥ ç´ æåˆ†æåº“ ({len(ads)} ä¸ªåˆ›æ„)")
    
    # æ„å»º index -> åˆ†æç»“æœçš„æ˜ å°„
    analysis_map = {}
    if ai_report:
        for ad_analysis in ai_report.get("individual_ads", []):
            idx = ad_analysis.get("index", -1)
            if idx >= 0:
                analysis_map[idx] = ad_analysis
    
    cols = st.columns(3)
    for idx, ad in enumerate(ads):
        with cols[idx % 3]:
            with st.container(border=True):
                # åª’ä½“é¢„è§ˆ
                if ad["preview_image_url"]:
                    st.image(ad["preview_image_url"], use_container_width=True)
                else:
                    st.text("No Preview")

                # æ ‡é¢˜ä¸çƒ­åº¦
                st.markdown(f"**{ad['title']}**")
                st.caption(f"ï¿½ çƒ­åº¦: {ad['intensity']} | ğŸ“… {ad['start_date'][:10] if ad['start_date'] else 'N/A'}")
                
                # è§†é¢‘/å›¾ç‰‡æ ‡ç­¾
                if ad["is_video"]:
                    st.caption(f"ğŸ¥ Video | by {ad['page_name']}")
                else:
                    st.caption(f"ğŸ–¼ï¸ Image | by {ad['page_name']}")

                # æ–‡æ¡ˆé¢„è§ˆ
                preview = (ad["text"] or "")[:80]
                st.text(preview + ("..." if len(ad["text"] or "") > 80 else ""))
                
                # --- AI åˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰---
                if idx in analysis_map:
                    analysis = analysis_map[idx]
                    category = analysis.get("category", {})
                    visual = analysis.get("visual_highlights", {})
                    copy_hl = analysis.get("copy_highlights", {})
                    promo = analysis.get("promo_intel", {})
                    score = analysis.get("creative_score", 0)
                    summary = analysis.get("one_line_summary", "")
                    
                    # ä¸€å¥è¯æ€»ç»“
                    if summary:
                        st.success(f"ï¿½ {summary}")
                    
                    # å±•å¼€æŸ¥çœ‹è¯¦ç»†åˆ†æ
                    with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†åˆ†æ"):
                        # åˆ†ç±»æ ‡ç­¾
                        st.markdown(f"**ç±»å‹:** {category.get('design_type', 'N/A')} | {category.get('content_strategy', 'N/A')}")
                        st.markdown(f"**åˆ›æ„è¯„åˆ†:** {'â­' * min(score, 10)} ({score}/10)")
                        
                        # ä¿ƒé”€æƒ…æŠ¥
                        if promo:
                            discount = promo.get('discount', '')
                            campaign = promo.get('campaign_name', '')
                            urgency = promo.get('urgency_elements', [])
                            if discount or campaign:
                                st.markdown(f"**ğŸ’° ä¿ƒé”€:** {discount} | {campaign}")
                            if urgency:
                                st.markdown(f"**â° ç´§è¿«æ„Ÿ:** {', '.join(urgency)}")
                        
                        # è§†è§‰äº®ç‚¹
                        st.markdown("**ï¿½ï¸ è§†è§‰:**")
                        st.markdown(f"- Hook: {visual.get('hook_element', 'N/A')}")
                        st.markdown(f"- åœºæ™¯: {visual.get('scene', 'N/A')}")
                        if visual.get('worth_learning'):
                            st.markdown(f"- âœ¨ {visual.get('worth_learning')}")
                        
                        # æ–‡æ¡ˆäº®ç‚¹
                        st.markdown("**ğŸ“ æ–‡æ¡ˆ:**")
                        st.markdown(f"- æ¡†æ¶: {copy_hl.get('framework', 'N/A')} | å—ä¼—: {copy_hl.get('target_audience', 'N/A')}")
                        triggers = copy_hl.get('emotional_triggers', [])
                        if triggers:
                            st.markdown(f"- æƒ…ç»ªè¯: {', '.join(triggers)}")
                        if copy_hl.get('worth_learning'):
                            st.markdown(f"- âœ¨ {copy_hl.get('worth_learning')}")

                # è¯¦æƒ…æŒ‰é’®
                if st.button("ğŸ” æŸ¥çœ‹åŸå§‹è¯¦æƒ…", key=f"{key_prefix}btn_{idx}"):
                    show_ad_details(ad)


# ================= Tab 1: Quick Scan =================
with tab_quick_scan:
    url_input = st.text_input(
        "Facebook Ad Library URL", 
        placeholder="https://www.facebook.com/ads/library/?...",
        key="quick_scan_url"
    )
    
    if st.button("ğŸš€ å¼€å§‹åˆ†æ (Start Scan)", type="primary", key="quick_scan_btn"):
        if not url_input:
            st.error("è¯·è¾“å…¥ URL")
        else:
            # 1) æ•°æ®è·å–
            raw_data = fetch_ads_from_apify(url_input, apify_token, results_limit)
            
            if not raw_data:
                st.warning("æœªè·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ URL æˆ– Tokenã€‚")
            else:
                # 2) æ¸…æ´—ä¸èšåˆ
                processed_ads = process_ads(raw_data)
                
                # 3) æ—¶é—´ç­›é€‰
                filtered_ads = filter_ads_by_time(processed_ads, time_filter_hours)
                
                st.session_state.processed_ads = filtered_ads
                st.session_state.current_scan_url = url_input
                
                if time_filter_hours:
                    st.success(f"âœ… æŠ“å–æˆåŠŸï¼Œå…± {len(processed_ads)} ä¸ªåˆ›æ„ï¼Œç­›é€‰å {len(filtered_ads)} ä¸ª")
                else:
                    st.success(f"âœ… æŠ“å–æˆåŠŸï¼Œå…±æ¸…æ´—å‡º {len(filtered_ads)} ä¸ªç‹¬ç«‹åˆ›æ„")

                # 4) AI åˆ†æ
                if gemini_key and filtered_ads:
                    with st.spinner("æ­£åœ¨è°ƒç”¨ Gemini è¿›è¡Œ AI ç­–ç•¥åˆ†æ..."):
                        st.session_state.ai_report = analyze_with_gemini(gemini_key, filtered_ads)
                else:
                    st.session_state.ai_report = None
    
    # æ¸²æŸ“ç»“æœ
    if st.session_state.processed_ads:
        render_ad_results(
            st.session_state.processed_ads, 
            st.session_state.ai_report,
            key_prefix="qs_"
        )


# ================= Tab 2: Brand Library =================
with tab_brand_library:
    st.markdown("### ğŸ“š å“ç‰Œèµ„äº§åº“")
    st.markdown("ä¿å­˜å¸¸ç”¨å“ç‰Œçš„å¹¿å‘Šåº“é“¾æ¥ï¼Œæ–¹ä¾¿å¿«é€Ÿåˆ†æã€‚")
    
    # --- æ·»åŠ å“ç‰Œ ---
    with st.expander("â• æ·»åŠ æ–°å“ç‰Œ", expanded=True):
        col1, col2 = st.columns([1, 2])
        with col1:
            new_brand_name = st.text_input("å“ç‰Œåç§°", placeholder="ä¾‹å¦‚: Jackery", key="new_brand_name")
        with col2:
            new_brand_url = st.text_input("Ad Library URL", placeholder="https://www.facebook.com/ads/library/?...", key="new_brand_url")
        
        if st.button("ğŸ’¾ ä¿å­˜å“ç‰Œ", key="save_brand_btn"):
            if new_brand_name and new_brand_url:
                # æ£€æŸ¥æ˜¯å¦é‡å¤
                existing_names = [b["name"] for b in st.session_state.brand_library]
                if new_brand_name in existing_names:
                    st.warning(f"å“ç‰Œ '{new_brand_name}' å·²å­˜åœ¨")
                else:
                    st.session_state.brand_library.append({
                        "name": new_brand_name,
                        "url": new_brand_url,
                        "added_at": datetime.now().isoformat()
                    })
                    st.success(f"âœ… å·²ä¿å­˜å“ç‰Œ: {new_brand_name}")
                    st.rerun()
            else:
                st.error("è¯·å¡«å†™å“ç‰Œåç§°å’Œ URL")
    
    st.divider()
    
    # --- å“ç‰Œåˆ—è¡¨ ---
    if st.session_state.brand_library:
        st.markdown("### å·²ä¿å­˜çš„å“ç‰Œ")
        
        for idx, brand in enumerate(st.session_state.brand_library):
            with st.container(border=True):
                col1, col2, col3 = st.columns([2, 1, 1])
                with col1:
                    st.markdown(f"**{brand['name']}**")
                    st.caption(f"æ·»åŠ æ—¶é—´: {brand['added_at'][:10]}")
                with col2:
                    if st.button("ğŸ” åˆ†æ", key=f"analyze_brand_{idx}"):
                        # è§¦å‘åˆ†æ
                        with st.spinner(f"æ­£åœ¨åˆ†æ {brand['name']}..."):
                            raw_data = fetch_ads_from_apify(brand["url"], apify_token, results_limit)
                            if raw_data:
                                processed = process_ads(raw_data)
                                filtered = filter_ads_by_time(processed, time_filter_hours)
                                st.session_state.processed_ads = filtered
                                st.session_state.current_scan_url = brand["url"]
                                
                                if gemini_key and filtered:
                                    st.session_state.ai_report = analyze_with_gemini(gemini_key, filtered)
                                else:
                                    st.session_state.ai_report = None
                                
                                st.success(f"âœ… å·²åŠ è½½ {brand['name']} çš„ {len(filtered)} ä¸ªå¹¿å‘Š")
                                st.rerun()
                            else:
                                st.error("è·å–æ•°æ®å¤±è´¥")
                with col3:
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_brand_{idx}"):
                        st.session_state.brand_library.pop(idx)
                        st.rerun()
        
        # æ˜¾ç¤ºå½“å‰åˆ†æç»“æœ
        if st.session_state.processed_ads and st.session_state.current_scan_url:
            st.divider()
            # æ‰¾åˆ°å½“å‰å“ç‰Œå
            current_brand = next(
                (b["name"] for b in st.session_state.brand_library 
                 if b["url"] == st.session_state.current_scan_url), 
                "Unknown"
            )
            st.markdown(f"### ğŸ“Š {current_brand} åˆ†æç»“æœ")
            render_ad_results(
                st.session_state.processed_ads,
                st.session_state.ai_report,
                key_prefix="bl_"
            )
    else:
        st.info("ğŸ“­ æš‚æ— ä¿å­˜çš„å“ç‰Œï¼Œè¯·æ·»åŠ ç¬¬ä¸€ä¸ªå“ç‰Œå¼€å§‹ä½¿ç”¨ã€‚")

